{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b16b6dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pad_sequences\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Assuming you have defined df, max_len, and tok (Tokenizer) earlier\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Train-test split\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m], df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m], test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m101\u001b[39m)\n\u001b[0;32m     11\u001b[0m X_train_mat \u001b[38;5;241m=\u001b[39m tok\u001b[38;5;241m.\u001b[39mtexts_to_sequences(X_train)\n\u001b[0;32m     12\u001b[0m X_test_mat \u001b[38;5;241m=\u001b[39m tok\u001b[38;5;241m.\u001b[39mtexts_to_sequences(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Assuming you have defined df, max_len, and tok (Tokenizer) earlier\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.3, random_state=101)\n",
    "\n",
    "X_train_mat = tok.texts_to_sequences(X_train)\n",
    "X_test_mat = tok.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_padded = pad_sequences(X_train_mat, maxlen=max_len)\n",
    "X_test_padded = pad_sequences(X_test_mat, maxlen=max_len)\n",
    "\n",
    "# Assuming you have trained and obtained a model named model_bi_lstm\n",
    "loaded_model = load_model('gru_model.h5')\n",
    "\n",
    "# Predict using the trained model on test data\n",
    "y_pred_prob = loaded_model.predict(X_test_padded, batch_size=128)\n",
    "y_pred = [1 if prob > 0.5 else 0 for prob in y_pred_prob]\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = sum(1 for true_label, pred_label in zip(y_test, y_pred) if true_label == pred_label)\n",
    "accuracy = correct_predictions / len(y_pred) * 100\n",
    "\n",
    "print('Correct Predictions:', correct_predictions)\n",
    "print('Wrong Predictions:', len(y_pred) - correct_predictions)\n",
    "print('Accuracy: {:.2f}%'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a453101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, GRU, Dense, Dropout, Conv1D, GlobalMaxPooling1D, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc6798b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1e4ad65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('IMDB.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b78cc037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['review', 'sentiment']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee4ca213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "blanks = []\n",
    "for i, rv, sn in df.itertuples():\n",
    "    if type(rv) == str and rv.isspace():\n",
    "        blanks.append(i)\n",
    "        \n",
    "if len(blanks) > 0:\n",
    "    print(f'There are {len(blanks)} empty space strings in the dataset')\n",
    "    df.drop(blanks, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1e965d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       49582\n",
       "sentiment        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6658e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1051b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length: 13704\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = df['review'].str.len().max()\n",
    "\n",
    "print(\"Max sequence length:\", max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "326e98c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words: 390931\n"
     ]
    }
   ],
   "source": [
    "words = set(word.lower() for sentence in df['review'] for word in sentence.split())\n",
    "n_unique_words = len(words)\n",
    "\n",
    "print(\"Unique words:\", n_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c289c3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        One of the other reviewers has mentioned that ...\n",
       "1        A wonderful little production. <br /><br />The...\n",
       "2        I thought this was a wonderful way to spend ti...\n",
       "3        Basically there's a family where a little boy ...\n",
       "4        Petter Mattei's \"Love in the Time of Money\" is...\n",
       "                               ...                        \n",
       "49995    I thought this movie did a down right good job...\n",
       "49996    Bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    I am a Catholic taught in parochial elementary...\n",
       "49998    I'm going to have to disagree with the previou...\n",
       "49999    No one expects the Star Trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0        positive\n",
       "1        positive\n",
       "2        positive\n",
       "3        negative\n",
       "4        positive\n",
       "           ...   \n",
       "49995    positive\n",
       "49996    negative\n",
       "49997    negative\n",
       "49998    negative\n",
       "49999    negative\n",
       "Name: sentiment, Length: 50000, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = df['review']\n",
    "y = df['sentiment']\n",
    "\n",
    "display(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "286e6cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "291a30ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "max_len = 150\n",
    "num_words = 1000\n",
    "\n",
    "tok = Tokenizer(num_words=num_words)\n",
    "tok.fit_on_texts(df['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aff43480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.3, random_state=101)\n",
    "\n",
    "X_train_mat = tok.texts_to_sequences(X_train)\n",
    "X_test_mat = tok.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_padded = pad_sequences(X_train_mat, maxlen=max_len)\n",
    "X_test_padded = pad_sequences(X_test_mat, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0858959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29f1e40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 115s 972ms/step\n",
      "Correct Predictions: 12990\n",
      "Wrong Predictions: 2010\n",
      "Accuracy: 86.60%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Assuming you have trained and obtained a model named model_bi_lstm\n",
    "loaded_model = load_model('gru_model.h5')\n",
    "# Predict using the trained model on test data\n",
    "y_pred_prob = loaded_model.predict(X_test_padded, batch_size=128)\n",
    "y_pred = [1 if prob > 0.5 else 0 for prob in y_pred_prob]\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = sum(1 for true_label, pred_label in zip(y_test, y_pred) if true_label == pred_label)\n",
    "accuracy = correct_predictions / len(y_pred) * 100\n",
    "\n",
    "print('Correct Predictions:', correct_predictions)\n",
    "print('Wrong Predictions:', len(y_pred) - correct_predictions)\n",
    "print('Accuracy: {:.2f}%'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5caf326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 3s 22ms/step\n",
      "Correct Predictions: 12893\n",
      "Wrong Predictions: 2107\n",
      "Accuracy: 85.95%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Assuming you have trained and obtained a model named model_bi_lstm\n",
    "loaded_model = load_model('imdbmodel/cnn_model.h5')\n",
    "# Predict using the trained model on test data\n",
    "y_pred_prob = loaded_model.predict(X_test_padded, batch_size=128)\n",
    "y_pred = [1 if prob > 0.5 else 0 for prob in y_pred_prob]\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = sum(1 for true_label, pred_label in zip(y_test, y_pred) if true_label == pred_label)\n",
    "accuracy = correct_predictions / len(y_pred) * 100\n",
    "\n",
    "print('Correct Predictions:', correct_predictions)\n",
    "print('Wrong Predictions:', len(y_pred) - correct_predictions)\n",
    "print('Accuracy: {:.2f}%'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de8ef1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 28s 238ms/step\n",
      "Correct Predictions: 12568\n",
      "Wrong Predictions: 2432\n",
      "Accuracy: 83.79%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Assuming you have trained and obtained a model named model_bi_lstm\n",
    "loaded_model = load_model('imdbmodel/rnn_model.h5')\n",
    "# Predict using the trained model on test data\n",
    "y_pred_prob = loaded_model.predict(X_test_padded, batch_size=128)\n",
    "y_pred = [1 if prob > 0.5 else 0 for prob in y_pred_prob]\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = sum(1 for true_label, pred_label in zip(y_test, y_pred) if true_label == pred_label)\n",
    "accuracy = correct_predictions / len(y_pred) * 100\n",
    "\n",
    "print('Correct Predictions:', correct_predictions)\n",
    "print('Wrong Predictions:', len(y_pred) - correct_predictions)\n",
    "print('Accuracy: {:.2f}%'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "179fb54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 48s 403ms/step\n",
      "Correct Predictions: 12840\n",
      "Wrong Predictions: 2160\n",
      "Accuracy: 85.60%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Assuming you have trained and obtained a model named model_bi_lstm\n",
    "loaded_model = load_model('imdbmodel/lstm_model.h5')\n",
    "# Predict using the trained model on test data\n",
    "y_pred_prob = loaded_model.predict(X_test_padded, batch_size=128)\n",
    "y_pred = [1 if prob > 0.5 else 0 for prob in y_pred_prob]\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = sum(1 for true_label, pred_label in zip(y_test, y_pred) if true_label == pred_label)\n",
    "accuracy = correct_predictions / len(y_pred) * 100\n",
    "\n",
    "print('Correct Predictions:', correct_predictions)\n",
    "print('Wrong Predictions:', len(y_pred) - correct_predictions)\n",
    "print('Accuracy: {:.2f}%'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a86add3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 88s 748ms/step\n",
      "Correct Predictions: 12845\n",
      "Wrong Predictions: 2155\n",
      "Accuracy: 85.63%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Assuming you have trained and obtained a model named model_bi_lstm\n",
    "loaded_model = load_model('imdbmodel/bidirectional_lstm_model.h5')\n",
    "# Predict using the trained model on test data\n",
    "y_pred_prob = loaded_model.predict(X_test_padded, batch_size=128)\n",
    "y_pred = [1 if prob > 0.5 else 0 for prob in y_pred_prob]\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = sum(1 for true_label, pred_label in zip(y_test, y_pred) if true_label == pred_label)\n",
    "accuracy = correct_predictions / len(y_pred) * 100\n",
    "\n",
    "print('Correct Predictions:', correct_predictions)\n",
    "print('Wrong Predictions:', len(y_pred) - correct_predictions)\n",
    "print('Accuracy: {:.2f}%'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "862f0f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 96s 811ms/step\n",
      "Correct Predictions: 12970\n",
      "Wrong Predictions: 2030\n",
      "Accuracy: 86.47%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Assuming you have trained and obtained a model named model_bi_lstm\n",
    "loaded_model = load_model('imdbmodel/bidirectional_gru_model.h5')\n",
    "# Predict using the trained model on test data\n",
    "y_pred_prob = loaded_model.predict(X_test_padded, batch_size=128)\n",
    "y_pred = [1 if prob > 0.5 else 0 for prob in y_pred_prob]\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = sum(1 for true_label, pred_label in zip(y_test, y_pred) if true_label == pred_label)\n",
    "accuracy = correct_predictions / len(y_pred) * 100\n",
    "\n",
    "print('Correct Predictions:', correct_predictions)\n",
    "print('Wrong Predictions:', len(y_pred) - correct_predictions)\n",
    "print('Accuracy: {:.2f}%'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f489c2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
